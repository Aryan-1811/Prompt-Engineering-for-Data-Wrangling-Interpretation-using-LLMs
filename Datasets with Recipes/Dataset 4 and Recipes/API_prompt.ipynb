{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4395295e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Wrangling Step\tTechnique Used\tDetails\n",
      "Check for balanced data\tNo\tNo balance check performed\n",
      "Sampling type\tRandom\ttrain_test_split without stratify\n",
      "Outliers removal\tNo\tOutliers visualized, but not removed\n",
      "Check for duplicates\tNo\tNo duplicate check performed\n",
      "Imputation of missing values\tnone\tNo missing values handling\n",
      "Drop columns\tYes\t'No' column dropped without replacement\n",
      "Encoding\tnone\tNo encoding performed\n",
      "Create new columns\tNo\tNo new columns created\n",
      "Feature selection\tNo\tNo feature selection performed\n",
      "Data scaling/standardisation\tYes\tStandardScaler used in pipeline\n",
      "Hyperparameter tuning\tNo\tNo hyperparameter tuning performed\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "from google import genai\n",
    "\n",
    "# Set your API key as environment variable\n",
    "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyBw5KldQIHCbwbhk42h-f20qyVMLSUIQvQ\"\n",
    "\n",
    "# Initialize Gemini client\n",
    "client = genai.Client()\n",
    "\n",
    "\n",
    "def extract_code_from_notebook(notebook_file: str) -> str:\n",
    "    \"\"\"Extract only code cells from a Jupyter notebook (.ipynb).\"\"\"\n",
    "    with open(notebook_file, \"r\", encoding=\"utf-8\") as f:\n",
    "        notebook_json = json.load(f)\n",
    "\n",
    "    code_cells = []\n",
    "    for cell in notebook_json.get(\"cells\", []):\n",
    "        if cell.get(\"cell_type\") == \"code\":\n",
    "            code_text = \"\".join(cell.get(\"source\", []))\n",
    "            if code_text.strip():\n",
    "                code_cells.append(code_text)\n",
    "\n",
    "    return \"\\n\\n\".join(code_cells)\n",
    "\n",
    "\n",
    "def analyze_notebook_with_gemini(prompt: str, notebook_file: str, model: str = \"gemini-2.0-flash\"):\n",
    "    \"\"\"Send prompt + extracted notebook code to Gemini and return response.\"\"\"\n",
    "    try:\n",
    "        code_content = extract_code_from_notebook(notebook_file)\n",
    "    except FileNotFoundError:\n",
    "        return f\"Notebook {notebook_file} not found.\"\n",
    "\n",
    "    full_prompt = f\"\"\"\n",
    "You are analyzing the notebook: {notebook_file}.\n",
    "\n",
    "Here are the extracted Python code cells:\n",
    "{code_content}\n",
    "\n",
    "User task:\n",
    "{prompt}\n",
    "\"\"\"\n",
    "\n",
    "    # Create a chat with Gemini\n",
    "    chat = client.chats.create(model=model)\n",
    "\n",
    "    # Send the message\n",
    "    response = chat.send_message(full_prompt)\n",
    "\n",
    "    return response.text\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "my_prompt = \"\"\"ROLE: You are a meticulous code auditor. The extracted Python code from the notebook appears ABOVE. \n",
    "\n",
    "TASK: Output ONE tab-separated table ONLY with columns:\n",
    "Data Wrangling Step<TAB>Technique Used<TAB>Details\n",
    "No extra text.\n",
    "\n",
    "ALLOWED LABELS (use exactly):\n",
    "- Check for balanced data: Yes / No\n",
    "- Sampling type: Random / Stratified / Oversampling / None\n",
    "- Outliers removal: Yes / No\n",
    "- Check for duplicates: Yes / No\n",
    "- Imputation of missing values: ignore / replace with text / use summary statistics / mixture of imputation techniques / multivariate / drop the missing value rows / drop the missing value columns / none\n",
    "- Drop columns: Yes / No\n",
    "- Encoding: Label Encoder / One hot encoding / catboost / mixture of encoding / dummy / none\n",
    "- Create new columns: Yes / No\n",
    "- Feature selection: Yes / No\n",
    "- Data scaling/standardisation: Yes / No\n",
    "- Hyperparameter tuning: Yes / No\n",
    "\n",
    "CRITICAL RULES:\n",
    "1) Create new columns = No when columns are derived from existing ones (pd.get_dummies/OneHotEncoder/arithmetic/parsing/type-casts/renames). Mark Yes only if truly new info not previously present.\n",
    "2) Drop columns = Yes only if a column is removed WITHOUT replacement (its information is not used to create other columns). If used to derive features and then dropped → Drop columns = No.\n",
    "3) Columns dropped AFTER EDA/visualisation/correlation/model-importance count as Feature selection = Yes (not Drop columns). Using correlation to prune features is feature selection.\n",
    "4) Log transforms are NOT scaling. Scaling = StandardScaler/MinMax/Robust/etc.\n",
    "5) Hyperparameter tuning = Yes only for systematic search (GridSearchCV/RandomizedSearchCV/Optuna/Bayesian). Manually setting parameters ≠ tuning.\n",
    "6) Sampling: \n",
    "   - train_test_split without stratify → Random\n",
    "   - train_test_split(..., stratify=target) or StratifiedKFold → Stratified\n",
    "   - SMOTE/undersampling/etc. → Oversampling\n",
    "   - none → None\n",
    "7) If multiple attempts appear, report the LAST operation that is actually used downstream.\n",
    "\n",
    "FEW-SHOT EXAMPLE (format to follow):\n",
    "Example Code:\n",
    "\n",
    "y = df[\"target\"]\n",
    "import seaborn as sns; sns.countplot(x=y)                # balance check\n",
    "X = df.drop(columns=[\"target\"])\n",
    "X[\"amt_log\"] = np.log1p(X[\"amt\"])                        # log ≠ scaling\n",
    "X = pd.get_dummies(X, columns=[\"cat\"])                   # derived dummies\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_tr, X_te, y_tr, y_te = train_test_split(X, y)          # Random\n",
    "# Post-EDA pruning:\n",
    "X_tr = X_tr.drop(columns=[\"highly_correlated_col\"])      # feature selection\n",
    "\n",
    "Expected TSV:\n",
    "Data Wrangling Step\tTTechnique Used\tDetails\n",
    "Check for balanced data\tYes\tcountplot on target\n",
    "Sampling type\tRandom\ttrain_test_split without stratify\n",
    "Outliers removal\tNo\tNo explicit filtering in code\n",
    "Check for duplicates\tNo\tNo duplicated/drop_duplicates used\n",
    "Imputation of missing values\tnone\tNo fillna/imputer/dropna\n",
    "Drop columns\tNo\tOriginal 'cat' removed only via get_dummies → replacement\n",
    "Encoding\tOne hot encoding\tpd.get_dummies on 'cat'\n",
    "Create new columns\tNo\tDerived (log, dummies) per rule\n",
    "Feature selection\tYes\tPost-EDA drop of 'highly_correlated_col'\n",
    "Data scaling/standardisation\tNo\tNo scaler used; log ≠ scaling\n",
    "Hyperparameter tuning\tNo\tNo Grid/Random/Optuna\n",
    "\n",
    "OUTPUT ORDER (exactly these 11 rows):\n",
    "Check for balanced data\n",
    "Sampling type\n",
    "Outliers removal\n",
    "Check for duplicates\n",
    "Imputation of missing values\n",
    "Drop columns\n",
    "Encoding\n",
    "Create new columns\n",
    "Feature selection\n",
    "Data scaling/standardisation\n",
    "Hyperparameter tuning\n",
    "\n",
    "SELF-CORRECTION (do once, silently): Before output, ensure you did NOT mark\n",
    "- Create new columns = Yes for derived/log/dummies/parsed/renamed,\n",
    "- Drop columns = Yes when the column’s info was used elsewhere.\n",
    "If violated, fix and output only the corrected TSV.\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "my_notebook = \"Dataset 4 Recipe 7.ipynb\"\n",
    "\n",
    "output = analyze_notebook_with_gemini(my_prompt, my_notebook)\n",
    "print(output)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4073587",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
